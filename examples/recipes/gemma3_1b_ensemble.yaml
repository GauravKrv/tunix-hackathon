# Ensemble Reward Training Recipe: Gemma3 1B

# Import base configurations
includes:
  - ../configs/models/gemma3_1b.yaml
  - ../configs/datasets/openassistant.yaml
  - ../configs/rewards/ensemble.yaml

# Training configuration
training:
  # Algorithm
  algorithm: "ppo"
  
  # Training hyperparameters
  num_epochs: 4
  steps_per_epoch: 1500
  learning_rate: 1.5e-5
  warmup_steps: 200
  
  # PPO specific
  ppo:
    num_ppo_epochs: 4
    mini_batch_size: 2
    gradient_accumulation_steps: 4
    ppo_clip_range: 0.2
    value_clip_range: 0.2
    kl_penalty: "kl"
    target_kl: 0.1
    gamma: 0.99
    lam: 0.95
    vf_coef: 0.1
    entropy_coef: 0.01
    
    # Ensemble-specific settings
    use_uncertainty_weighting: true
    uncertainty_penalty_coef: 0.05
  
  # Optimization
  optimizer:
    type: "adamw"
    betas: [0.9, 0.999]
    eps: 1e-8
    weight_decay: 0.01
  
  # Learning rate scheduler
  scheduler:
    type: "linear"
    warmup_ratio: 0.1
  
  # Generation during training
  generation:
    max_new_tokens: 384
    temperature: 0.8
    top_p: 0.9
    do_sample: true
  
  # Logging
  logging:
    log_interval: 10
    eval_interval: 100
    save_interval: 500
    log_dir: "logs/gemma3_1b_ensemble"
    
  # Evaluation
  evaluation:
    num_samples: 200
    metrics: ["reward", "reward_uncertainty", "reward_disagreement", "kl", "length", "perplexity"]
    
  # Checkpointing
  checkpointing:
    save_dir: "checkpoints/gemma3_1b_ensemble"
    save_total_limit: 5
    save_best: true
    metric_for_best_model: "reward"
    greater_is_better: true

# Hardware configuration
hardware:
  device: "cuda"
  mixed_precision: "bf16"
  gradient_checkpointing: true
  
  # Multi-GPU
  distributed:
    enabled: false
    backend: "nccl"
    find_unused_parameters: false
  
  # Memory optimization
  memory:
    max_memory_per_gpu: null
    cpu_offload: false

# Experiment tracking
tracking:
  enabled: true
  backend: "wandb"
  project_name: "rlhf-training"
  run_name: "gemma3_1b_ensemble"
  tags: ["gemma3", "1b", "ensemble", "ppo"]
  
  # Log additional artifacts
  log_model: true
  log_gradients: false
  log_code: true

# Misc
seed: 42
